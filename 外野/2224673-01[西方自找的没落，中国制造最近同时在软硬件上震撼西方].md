
*****

####  机吉斯卡  
##### 1#       楼主       发表于 2024-12-27 16:21

 本帖最后由 机吉斯卡 于 2024-12-27 16:30 编辑 

https://weibo.com/1560906700/5116227597110418

这几天刷推很明显的感觉到英文技术社区对中国AI产业的进步速度处于一种半震动半懵逼的状态，应激来源主要是两个，一个是宇树（Unitree）的轮足式机器狗B2-W，另一个是开源MoE模型DeepSeek-V3。

宇树在早年基本上属于是波士顿动力的跟班，产品形态完全照猫画虎，商业上瞄准的也是低配平替生态位，没有太大的吸引力，但从B系列型号开始，宇树的机器狗就在灵活性上可以和波士顿动力平起平坐了。

B2-W的意外在于切换了技术线，用运动性更高但平衡性同时也更难的动轮方案取代了B2还在沿用四足方案，然后在一年时间里完成了能在户外环境里跋山涉水的训练，很多美国人在视频底下说这一定是CGI的画面，不知道是真串还是心态炸了。

波士顿在机器狗身上也曾短暂用过动轮方案，或者说它测过的方案远比宇树要多——公司成立时长摆在那里——但是作为行业先驱，它连保持一家美国公司的实体都办不到了。

现代汽车2020年以打折价从软银手里买了波士顿动力，正值软银账面巨亏需要回血，而软银当初又是在2017年从Google那里买到手的，Google为什么卖呢，因为觉得太烧钱了，亏不起。

这理由就很离谱，美国的风险资本系统对于亏损的容忍度本来就是全球最高的，没有之一，对于前沿性的研究，砸钱画饼是再寻常不过了的——看这两年硅谷在AI上的投入产出比就知道了——但波士顿动力何以在独一档的地位上被当成不良资产卖来卖去？

那头房间里的大象，美国的科技行业普遍都装作看不到：美国人，如今的美国人，从投行到企业，从CEO到程序员，从纽约到湾区，对制造业的厌弃已经成为本能了。

A16Z的合伙人马克·安德森2011年在「华尔街日报」写了那篇流传甚广的代表作「软件吞噬世界」，大概意思是，边际成本极低的软件公司注定接管一切水草繁盛之地，和这种可以提供指数级增长的生意比起来，其他的行业都不够看。

并不是说马克·安德森的表达有问题，后面这十几年来的现实走向，也确实在证明这条攫取规模化利润的回报是最高的，但美国人的路径依赖到最后必然带来一整代人丧失制造能力的结果。

这里说的丧失制造能力，并不是说丧失制造兴趣或是热情，我前段时间拜访了深圳一家逆向海淘公司，业务就是把华强北的电子配件做成可索引的结构化目录，然后提供从采购到验货再到发包的全流程服务，最大的买方就是美国的DIY市场和高校学生，他们之所以要不远万里的等上几个星期委托中国人来买东西，就是因为在诺大的美国本土，根本找不到供应链。

然后那些学生也只有在读书时才有真正尝试制造某些东西的机会，到了要去大公司里上班领薪后，再也没人愿意把手弄脏了。

但软件终究不能脱离硬件运行，哪怕硬件生产的附加值再不够看，基于采集一手物理数据的入口，制造商腰板硬起来后去做全套解决方案，只取决于能不能组建好的工程师团队，反过来却不一样，制造订单长期外包出去，它就变成产业链配套回不来了。

所以像是多旋翼无人机和四足机器狗这类新兴科技萌芽的原型机一般都还是产自有着试错资本的欧美，也就是所谓「从零到一」的过程，而在「从一到十」的落地阶段，中国的追赶成果就会开始密集呈现，进入「从十到百」的量产之后，中国的供应链成本直接杀死比赛。

波士顿动力的机器人最早在网上爆火的时候，Google X的负责人在内部备忘录里说他已经和媒体沟通了，希望不要让视频和Google扯上太大关系，是不是很迷惑，这么牛逼的事情，你作为母公司非但不高兴，还想躲起来，现在你们懂得这种顾虑从何而来了，就是觉得贵为软件巨头的Google去卷袖子干制造的活儿太卑贱了呗。

当然美国也还有马斯克这样的建设者（Builder），但你要知道马斯克的故事之所以动人，是因为他这样的人现在是极度稀缺的，而且长期以来不受主流科技业界待见，完全是靠逆常识的成就——造汽车，造火箭，造隧道，这都是硅谷唯恐避之不及的事情——去一步步打脸打出来的名声。

如果说宇树是在硬件上引起了一波怀疑现实的热度，那么DeepSeek则在软件的原生地盘，把大模型厂商都给硬控住了。

在微软、Meta、Google都在奔着10万卡集群去做大模型训练时，DeepSeek在2000个GPU上，花了不到600万美金和2个月的时间，就实现了对齐GPT-4o和Claude 3.5 Sonnet的测试结果。

DeepSeek-V2在半年前就火过一波，但那会儿的叙事还相对符合旧版本的预期：中国AI公司推出了低成本的开源模型，想要成为行业里的价格屠夫，中国人就擅长做这种便宜耐用的东西，只要不去和顶级产品比较，能用是肯定的。

但V3则完全不同了，它把成本降了10倍以上，同时质量却能比肩t1阵营，关键还是开源的，相关推文的评论区全是「中国人咋做到的？」

虽然但是，后发的大模型可以通过知识蒸馏等手段实现性价比更高的训练——类似你学习牛顿三定律的速度降低的斜率也在有利于追赶者，肯定比牛顿本人琢磨出定律的速度要快——成本，但匪夷所思的效率提升，是很难用已知训练方法来归纳的，它一定是是在底层架构上做了不同于其他巨头的创新。

另一个角度更有意思，如果针对中国的AI芯片禁售政策最后产生的后果，是让中国的大模型公司不得不在算力受限的约束下实现了效率更高的解决方案，这种适得其反的剧情就太讽刺了。

DeepSeek的创始人梁文锋之前也说过，公司差的从来都不是钱，而是高端芯片被禁运。

所以中国的大模型公司，像是字节和阿里这样的大厂，卡能管够，把年收入的1/10拿出来卷AI，问题不大，但初创公司没这么多弹药，保持不下牌桌的唯一方法就是玩命创新。

李开复今年也一直在表达一个观点，中国做AI的优势从来不是在不设预算上限的情况下去做突破性研究，而是在好、快、便宜和可靠性之间找出最优解。

零一和DeepSeek用的都是MoE（混合专家）模式，相当于是在事先准备的高质量数据集上去做特定训练，不能说在跑分上完全没有水分，但市场并不关心原理，只要质价比够看，就一定会有竞争力。

当然DeepSeek不太一样的是，它不太缺卡，2021年就囤了1万张英伟达A100，那会儿ChatGPT还没影呢，和Meta为了元宇宙囤卡却阴差阳错的赶上AI浪潮很像，DeepSeek买那么多卡，是为了做量化交易⋯⋯

我最早对梁文锋有印象，是「西蒙斯传」里有他写的序，西蒙斯是文艺复兴科技公司的创始人，用算法模型去做自动化投资的开创者，梁文锋当时管着600亿人民币的量化私募，写序属于顺理成章的给行业祖师爷致敬。

交待这个背景，是想说，梁文锋的几家公司，从量化交易做到大模型开发，并不是一个金融转为科技的过程，而是数学技能在两个应用场景之间的切换，投资的目的是预测市场，大模型的原理也是预测Token。

后来看过几次梁文锋的采访，对他的印象很好，非常清醒和聪明的一个人，我贴几段你们感受一下：

「暗涌」：大部分中国公司都选择既要模型又要应用，为什么DeepSeek目前选择只做研究探索？

梁文锋：因为我们觉得现在最重要的是参与到全球创新的浪潮里去。过去很多年，中国公司习惯了别人做技术创新，我们拿过来做应用变现，但这并非是一种理所当然。这一波浪潮里，我们的出发点，就不是趁机赚一笔，而是走到技术的前沿，去推动整个生态发展。

「暗涌」：互联网和移动互联网时代留给大部分人的惯性认知是，美国擅长搞技术创新，中国更擅长做应用。

梁文锋：我们认为随着经济发展，中国也要逐步成为贡献者，而不是一直搭便车。过去三十多年IT浪潮里，我们基本没有参与到真正的技术创新里。我们已经习惯摩尔定律从天而降，躺在家里18个月就会出来更好的硬件和软件。Scaling Law也在被如此对待。但其实，这是西方主导的技术社区一代代孜孜不倦创造出来的，只因为之前我们没有参与这个过程，以至于忽视了它的存在。

「暗涌」：但这种选择放在中国语境里，也过于奢侈。大模型是一个重投入游戏，不是所有公司都有资本只去研究创新，而不是先考虑商业化。

梁文锋：创新的成本肯定不低，过去那种拿来主义的惯性也和过去的国情有关。但现在，你看无论中国的经济体量，还是字节、腾讯这些大厂的利润，放在全球都不低。我们创新缺的肯定不是资本，而是缺乏信心以及不知道怎么组织高密度的人才实现有效的创新。

「暗涌」：但做大模型，单纯的技术领先也很难形成绝对优势，你们赌的那个更大的东西是什么？

梁文锋：我们看到的是中国AI不可能永远处在跟随的位置。我们经常说中国AI和美国有一两年差距，但真实的gap是原创和模仿之差。如果这个不改变，中国永远只能是追随者，所以有些探索也是逃不掉的。英伟达的领先，不只是一个公司的努力，而是整个西方技术社区和产业共同努力的结果。他们能看到下一代的技术趋势，手里有路线图。中国AI的发展，同样需要这样的生态。很多国产芯片发展不起来，也是因为缺乏配套的技术社区，只有第二手消息，所以中国必然需要有人站到技术的前沿。

「暗涌」：很多大模型公司都执着地去海外挖人，很多人觉得这个领域前50名的顶尖人才可能都不在中国的公司，你们的人都来自哪里？

梁文锋：V2模型没有海外回来的人，都是本土的。前50名顶尖人才可能不在中国，但也许我们能自己打造这样的人。

「暗涌」：所以你对这件事也是乐观的？

梁文锋：我是八十年代在广东一个五线城市长大的。我的父亲是小学老师，九十年代，广东赚钱机会很多，当时有不少家长到我家里来，基本就是家长觉得读书没用。但现在回去看，观念都变了。因为钱不好赚了，连开出租车的机会可能都没了。一代人的时间就变了。以后硬核创新会越来越多。现在可能还不容易被理解，是因为整个社会群体需要被事实教育。当这个社会让硬核创新的人功成名就，群体性想法就会改变。我们只是还需要一堆事实和一个过程。

⋯⋯

是不是很牛逼？反正我是被圈粉了，做最难的事情，还要站着把钱赚了，一切信念都基于对真正价值的尊重和判断，这样的80后、90后越来越多的站上了主流舞台，让人非常宽慰，你可以说他们在过去是所谓的「小镇做题家」，但做题怎么了，参与世界未来的塑造，就是最有挑战性的题，喜欢解这样的题，才有乐趣啊。

﹍﹍﹍

评分

 参与人数 2战斗力 +2

|昵称|战斗力|理由|
|----|---|---|
| 赛文欧德| + 1|好评加鹅|
| hbxsdfx| + 1|中年人被粉了，淦|

查看全部评分

*****

####  CCauchy  
##### 2#       发表于 2024-12-27 16:25

量化交易是指AI量化交易吗? 这不还是AI, 也不算阴差阳错吧

*****

####  Van夫膜开  
##### 3#       发表于 2024-12-27 16:28

从搞量化私募直接转行搞LLM，这个决心和眼界是真的牛逼

*****

####  amzonme  
##### 4#       发表于 2024-12-27 16:28

deepseek的软文？

*****

####  出逃白鲸  
##### 5#       发表于 2024-12-27 16:29

 本帖最后由 出逃白鲸 于 2024-12-27 16:32 编辑 

楼主没贴作者名字，个人凭感觉这个作者肯定不是制造业的，说了半天很空洞。

观点也许对，但内容空，套话多，爱用无关例证，这种行文像是经常写蹭热度文章忽悠外行留下的习惯

*****

####  魔灵高达  
##### 6#       发表于 2024-12-27 16:31

软文<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

*****

####  netplaying  
##### 7#       发表于 2024-12-27 16:32

等chatgpt降价再说吧

*****

####  小李子大脸猫  
##### 8#       发表于 2024-12-27 16:33

以六代机为首的竞争刚好体现美国洛克希德马丁等制造业公司的极限，这就是美国人临盆难产面对的刚体洛希极限

*****

####  绝地潜兵  
##### 9#       发表于 2024-12-27 16:34

 本帖最后由 绝地潜兵 于 2024-12-27 16:35 编辑 

机器人确实发展得好，但那个过程是在臆想吧。感觉是deepseek软文

*****

####  木水风铃  
##### 10#       发表于 2024-12-27 16:35

今天倒是微博上看到几个说v3效率惊人的，不过还是等能用到手再说吧

—— 来自 HUAWEI NOH-AN00, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v3.0.0.81-alpha

*****

####  壹十  
##### 11#       发表于 2024-12-27 16:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67035537&amp;ptid=2224673" target="_blank">出逃白鲸 发表于 2024-12-27 16:29</a>

楼主没贴作者名字，个人凭感觉这个作者肯定不是制造业的，说了半天很空洞。

观点也许对，但内容空，套话多 ...</blockquote>
第一行就是微博原文链接

*****

####  alixsander  
##### 12#       发表于 2024-12-27 16:39

<blockquote>木水风铃 发表于 2024-12-27 16:35
今天倒是微博上看到几个说v3效率惊人的，不过还是等能用到手再说吧

—— 来自 HUAWEI NOH-AN00, Android 1 ...</blockquote>
V3你上他们官网就能用了。论文和权重也都开放了下载了

*****

####  泰坦失足  
##### 13#       发表于 2024-12-27 16:40

关注的几个傻X博主同时发了QVQ的商稿，对通义千问的好感大降。

另外之前Deepseek的API看了半天，发现没写多模态输入在哪。这次的V3也一样没多模态。

隔壁OpenAI除了翻车的Sora，多模态的4o，长推理的o1。得到的结果就是一个可以实时理解视频流和音频流并即时输出的模型，而不是走 视频/音频-&gt;文字-&gt;音频TTS的道路

*****

####  木板春香  
##### 14#       发表于 2024-12-27 16:42

 做自媒体的人

*****

####  moekyo  
##### 15#       发表于 2024-12-27 16:45

我只能说我在推上搜DeepSeek基本都是吹的，和半年多之前的千问差不多

*****

####  张元英  
##### 16#       发表于 2024-12-27 16:48

A16Z的合伙人马克·安德森2011年在「华尔街日报」写了那篇流传甚广的代表作「软件吞噬世界」

这篇文章可以转一下

*****

####  bbk6rz  
##### 17#       发表于 2024-12-27 16:51

以前熟知的杭州大企业就一个阿里。现在知道的，有游戏科学，宇树，deepseek。

*****

####  a4ac7  
##### 18#       发表于 2024-12-27 16:51

 本帖最后由 a4ac7 于 2024-12-27 17:03 编辑 

在文字处理方面，感觉o1是有挺大提升的

拿坛友这个对子问

<img src="https://p.sda1.dev/21/d5695a88bb411889bf604e06df274313/image.jpg" referrerpolicy="no-referrer">

o1回答至少字数和结构对上了，4o和seek半斤八两，不过能达到4o也很nb了

试了下deepseek的深度思考，有点意思

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.2.91

*****

####  流缨  
##### 19#       发表于 2024-12-27 16:55

软文，但是deepseek真的不错，这几天TWZ的文章我都用它翻译了看，有个回复里有个英文非主流词 '$hort' 都翻译对了，试了一下传统的翻译器都没做到

*****

####  overflowal  
##### 20#       发表于 2024-12-27 17:00

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67035649&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2024-12-27 16:40</a>

关注的几个傻X博主同时发了QVQ的商稿，对通义千问的好感大降。

另外之前Deepseek的API看了半天，发现没写多 ...</blockquote>
deepseek本来就不是个多模态模型啊。

*****

####  yuialon  
##### 21#       发表于 2024-12-27 17:03

<img src="https://static.saraba1st.com/image/smiley/face2017/034.png" referrerpolicy="no-referrer">

纯软广，预训练技术路线已经到头了

下一代路线如果摸索出来，预训练直接被扫进垃圾桶

至于幻方转AI，纯被证监会制裁转行罢了，可以搜下《证券市场程序化交易管理规定》

*****

####  洛拉斯  
##### 22#       发表于 2024-12-27 17:05

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67035753&amp;ptid=2224673" target="_blank">a4ac7 发表于 2024-12-27 16:51</a>
在文字处理方面，感觉o1是有挺大提升的

拿坛友这个对子问</blockquote>
下联你贴出来一下可以吗

*****

####  冯恩在写小说  
##### 23#       发表于 2024-12-27 17:07

不能这么拼，波士顿动力仍然有西方企业的核心技术优势：画饼

*****

####  overflowal  
##### 24#       发表于 2024-12-27 17:12

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67035855&amp;ptid=2224673" target="_blank">yuialon 发表于 2024-12-27 17:03</a>

纯软广，预训练技术路线已经到头了

下一代路线如果摸索出来，预训练直接被扫进垃圾桶</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/048.png" referrerpolicy="no-referrer">这有啥好软广的。x上各路ai圈的推主这两天都在谈deepseek的新模型，openrouter上到deepseek api的流量翻了3倍。

*****

####  基本农田  
##### 25#       发表于 2024-12-27 17:14

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67035579&amp;ptid=2224673" target="_blank">小李子大脸猫 发表于 2024-12-27 16:33</a>
以六代机为首的竞争刚好体现美国洛克希德马丁等制造业公司的极限，这就是美国人临盆难产面对的刚体洛希极限 ...</blockquote>
今年各方面的进步，表明东大在技术创新能力上已经正式全面超越欧美

*****

####  qratosones1337  
##### 26#       发表于 2024-12-27 17:17

人家模型开源了，技术报告发了，官网也上线了，楼上一堆刷软文的是只会复读么？

*****

####  笨拙的机器人  
##### 27#       发表于 2024-12-27 17:26

一眼deepseek软文，deepseek牛逼没错，也不至于翻到豆包千问前面去

*****

####  a4ac7  
##### 28#       发表于 2024-12-27 17:27

 本帖最后由 a4ac7 于 2024-12-27 17:34 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67035868&amp;ptid=2224673" target="_blank">洛拉斯 发表于 2024-12-27 17:05</a>
下联你贴出来一下可以吗</blockquote><strong>问题：</strong>
帮我对个对子，一艘两攻共三架飞机四款新品搞得五角大楼六神无主七上八下酒后加班十分难受

<strong>ChatGPT o1：</strong>
下面是一条与原句在字数和节奏上相匹配的下联示例，可供参考。为了与上联同样带有“跳过九”的趣味，且在内容上与“五角大楼”“六神无主”“七上八下”等处形成对应，下联也巧用了数字与词语搭配，保持了同样的诙谐气质。

<strong>上联：</strong>
一艘两攻共三架飞机四款新品搞得五角大楼六神无主七上八下酒后加班十分难受

<strong>下联（示例）：</strong>
一言两疑惹三大盟友四处施压惊动五角白宫六魄无存七扯八纠酒尽方言十分狼狈

<strong>拆分对照与释义：</strong>  <strong>一言 两疑</strong>
上联“一艘 两攻”，下联用“一言 两疑”呼应，皆为四字，暗示“说一句话却生出两种猜忌”。

<strong>惹三大盟友</strong>
对应上联“共三架飞机”。“三大盟友”既点出“三”这个数字，也让情节更加国际化。

<strong>四处施压</strong>
对应上联“四款新品”，同样以“四”字开头，表达多方向、多方面的动作。

<strong>惊动五角白宫</strong>
上联是“搞得五角大楼”，下联改为“惊动五角白宫”，既保留“五角”这一核心元素，又把“大楼”变成“白宫”，进一步衬托美方焦虑。

<strong>六魄无存</strong>
对应上联“六神无主”，继续使用“六”字＋“魄”来与“神”对仗，营造神魂颠倒之感。

<strong>七扯八纠</strong>
上联“七上八下”，下联用“七扯八纠”，依旧是数字七、八的并列，形容混乱局面。

<strong>酒尽方言</strong>
上联是“酒后加班”，下联“酒尽方言”则表现“酒喝光了才开始胡说”之意，与加班后烦躁相呼应。

<strong>十分狼狈</strong>
对应“十分难受”，以“狼狈”烘托窘迫、糟糕的状态，跟“难受”形成近义映衬。 

如果觉得用词或主题还可以进一步润色，也可以在保持字数和数词位置不变的前提下，根据实际需要做微调。希望对你的创作有所启发!

<strong>ChatGPT 4o：</strong>
<strong>上联：</strong>
一艘两攻共三架飞机四款新品搞得五角大楼六神无主七上八下酒后加班十分难受

<strong>下联：</strong>
九天八荒携七条龙舟六尺金枪破得五岳四海三江两岸一战风流

<strong>Deepseek：</strong>
十全九美有八斗才七步成诗六艺精通五湖四海三心二意一夜成名百般得意

<strong>Deepseek（带深度思考）：</strong>
这是一句带有数字和对仗色彩的顺口溜，描述了一种混乱和无奈的场景。下面是对这句顺口溜的解释和可能的“对子”：

<strong>原句：</strong>
一艘两攻共三架飞机四款新品搞得五角大楼六神无主七上八下酒后加班十分难受

<strong>解释：</strong>  <strong>一艘两攻：</strong>
可能指一艘具有两种攻击能力的舰船。

<strong>共三架飞机：</strong>
指共有三架飞机。

<strong>四款新品：</strong>
指四种新产品或新装备。

<strong>搞得五角大楼：</strong>
可能指这些装备让五角大楼（美国国防部）感到困扰。

<strong>六神无主：</strong>
形容非常慌乱，没有头绪。

<strong>七上八下：</strong>
形容心情不安，忐忑不定。

<strong>酒后加班：</strong>
指在喝酒之后还要加班工作。

<strong>十分难受：</strong>
形容非常不舒服，可能指身体或心理上的不适。 

<strong>对子：</strong>
（上联）一艘两攻共三架飞机四款新品搞得五角大楼六神无主七上八下酒后加班十分难受

（下联）一面五星展六尺红旗七彩光芒照亮八方天地九天揽月十分自豪

<strong>解释：</strong>  <strong>一面五星：</strong>
指一面五星红旗。

<strong>展六尺红旗：</strong>
展开六尺长的红旗。

<strong>七彩光芒：</strong>
形容红旗在阳光下闪耀着七彩的光芒。

<strong>照亮八方天地：</strong>
指红旗的光芒照亮了四周。

<strong>九天揽月：</strong>
指登月等航天成就。

<strong>十分自豪：</strong>
形容对国家成就感到非常自豪。 

这个对子通过对比原句的混乱和无奈，表达了对国家成就的自豪感。

顺便这个第一次 Deepseek 带深度思考对的，“一花两叶共三春花开四季芬芳扑鼻使得五湖四海六合同春七彩斑斓八方来客九九归一十分和谐”，看来不太稳定

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.2.91

*****

####  overflowal  
##### 29#       发表于 2024-12-27 17:32

 本帖最后由 overflowal 于 2024-12-27 17:33 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036030&amp;ptid=2224673" target="_blank">笨拙的机器人 发表于 2024-12-27 17:26</a>

一眼deepseek软文，deepseek牛逼没错，也不至于翻到豆包千问前面去</blockquote>
大家觉得deepseek牛逼是因为它在各种benchmark表现真的跟闭源模型硬刚了啊，他们自己报告里也写了和qwen的对比。别这里虚空排位干不过豆包千问

*****

####  qratosones1337  
##### 30#       发表于 2024-12-27 17:32

 本帖最后由 qratosones1337 于 2024-12-27 17:39 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036030&amp;ptid=2224673" target="_blank">笨拙的机器人 发表于 2024-12-27 17:26</a>

一眼deepseek软文，deepseek牛逼没错，也不至于翻到豆包千问前面去</blockquote>
笑死，论模型能力，豆包就是个CJB，也就是产品做的比较好而已，现在DeepSeek和Qwen就是国内的Top-2。然后Qwen现在已经放弃了超大模型冲SOTA了，专注于做中小模型，跟DeepSeek生态位正好错开了。

*****

####  chachi  
##### 31#       发表于 2024-12-27 17:40

坐等千问qwq 

*****

####  马车夫  
##### 32#       发表于 2024-12-27 17:41

美帝这几年甚至是十多年前万物转码的后遗症，认识不少学机械EE的纷纷抛弃制造业，纯coding又不是什么要智商的玩意儿，，

剩下的本土制造业学生疯狂追星马斯克这根独苗，tesla的实习目测不给钱简历都收爆

*****

####  overflowal  
##### 33#       发表于 2024-12-27 17:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67035969&amp;ptid=2224673" target="_blank">qratosones1337 发表于 2024-12-27 17:17</a>

人家模型开源了，技术报告发了，官网也上线了，楼上一堆刷软文的是只会复读么？ ...</blockquote>
国内公司发了一个堪比商业闭源模型的开源模型，技术报告写的清清楚楚，国外ai圈子讨论的热火朝天。

国内自媒体反应过来跟着吹一下，一群人第一反应是软文大内宣，我也是服

*****

####  笨拙的机器人  
##### 34#       发表于 2024-12-27 17:45

<blockquote>overflowal 发表于 2024-12-27 17:32
大家觉得deepseek牛逼是因为它在各种benchmark表现真的跟闭源模型硬刚了啊，他们自己报告里也写了和qwen的 ...</blockquote>
别跑题，我的重点在软文，前面把宇树抬出来是因为直接说deepseek啊排行榜啊这种抽象的东西，你不容易有感。先用宇树吸睛，再吹deepseek，我的雷达响了

*****

####  泰坦失足  
##### 35#       发表于 2024-12-27 17:48

这玩意尺寸是671B，啥卡能放下啊<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">. llama 3.2的405b都挺抽象的了.

*****

####  overflowal  
##### 36#       发表于 2024-12-27 17:50

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036132&amp;ptid=2224673" target="_blank">笨拙的机器人 发表于 2024-12-27 17:45</a>

别跑题，我的重点在软文，前面把宇树抬出来是因为直接说deepseek啊排行榜啊这种抽象的东西，你不容易有感 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/048.png" referrerpolicy="no-referrer">那行吧，就是软文。deepseek这公司怎么会出现在在公众视野呢，肯定是软文没跑了

*****

####  钱如命  
##### 37#       发表于 2024-12-27 17:52

这篇文章确实是标准的软文结构啊<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">
标题是“西方vs中国”的标准引战标题党吸引眼球，开头讲了大概1/4的机械狗发展历程（宇树只是提了一嘴，更多的是“理性客观公正”地分析局势）
然后剩下3/4，“接下来说说软件”的转场之后，就是长篇大论“只针对”deepseek的夸奖和吹捧，放了一大段老板的个人访谈
直到最后文末总结，也把标题和开头扔在一边，专注于“优秀的老板和企业家”这个部分
就算他吹的是现在蓝星第一，那也是软文啊（）

—— 来自 HUAWEI ALN-AL80, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.1.2

*****

####  med  
##### 38#       发表于 2024-12-27 17:53

再加一个游科，软文就更明显了 <img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

*****

####  overflowal  
##### 39#       发表于 2024-12-27 17:55

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036160&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2024-12-27 17:48</a>

这玩意尺寸是671B，啥卡能放下啊. llama 3.2的405b都挺抽象的了.</blockquote>
单卡是放不下了，真想跑可以尝试放到内存用CPU跑，应该速度是能用的。因为是MoE架构<img src="https://static.saraba1st.com/image/smiley/face2017/048.png" referrerpolicy="no-referrer">

*****

####  橋白  
##### 40#       发表于 2024-12-27 17:55

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036160&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2024-12-27 17:48</a>
这玩意尺寸是671B，啥卡能放下啊. llama 3.2的405b都挺抽象的了.</blockquote>
本来就放不下啊 moe结构说白了是省电费又不是省显存…

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)


*****

####  qratosones1337  
##### 41#       发表于 2024-12-27 18:07

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036123&amp;ptid=2224673" target="_blank">overflowal 发表于 2024-12-27 17:42</a>

国内公司发了一个堪比商业闭源模型的开源模型，技术报告写的清清楚楚，国外ai圈子讨论的热火朝天。

国内 ...</blockquote>
说明泥潭喜欢不懂装懂的懂哥太多了，啥都想插一句嘴，然后自己又根本不懂（甚至可能都没到一知半解的地步），自然就只能甩锅软文咯。毕竟只要“雷达响了”就自动立于不败之地了

*****

####  qratosones1337  
##### 42#       发表于 2024-12-27 18:08

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036219&amp;ptid=2224673" target="_blank">橋白 发表于 2024-12-27 17:55</a>

本来就放不下啊 moe结构说白了是省电费又不是省显存…

论坛助手,iPhone</blockquote>
利好超大显存的廉价推理卡，正好这次DeepSeek开源的时候也同步发布了昇腾可用的推理方案，估计DeepSeek自己可能已经在用Atlas300I Duo来推理了（这玩意有96G显存，一张卡不到3W块钱）


*****

####  qratosones1337  
##### 43#       发表于 2024-12-27 18:10

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036160&amp;ptid=2224673" target="_blank">泰坦失足 发表于 2024-12-27 17:48</a>

这玩意尺寸是671B，啥卡能放下啊. llama 3.2的405b都挺抽象的了.</blockquote>
华为有个Atlas300I，96G显存版本单卡售价3W块钱不到，正好这次模型Release的时候连MindIE推理镜像都一起发了

*****

####  yanjunle  
##### 44#       发表于 2024-12-27 18:13

 本帖最后由 yanjunle 于 2024-12-27 18:14 编辑 

deepseek-v3发布最思细恐极的一点不是涨价预告吗，不知道为什么没看到什么相关的讨论。

幻方是今年这轮api价格战的发动者，5月份靠“模型结构创新+超强infra+不求盈利只求打平推理成本”实现了一块钱一百万token还能维持50%毛利，可以认为幻方拥有世界上最顶尖不用加之一的llm工程团队。

以及目前llm性能增长的方向是test-time scaling，qwq和deepseek-r1看起来都是走成倍增加输出token数来解决更困难的问题的路线，输出token数增加会导致使用成本急剧上涨（比如前几天o3发布时号称做一道题要用掉3500刀），只能寄希望于降低token输出单价来降低整体使用成本。

然而deepseek涨价了，说明即使世界最强工程团队也控制不住llm推理成本了，llm智价比很可能已经到顶了，未来都是1块钱2分货10块钱3分货了<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

*****

####  笨拙的机器人  
##### 45#       发表于 2024-12-27 18:14

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036283&amp;ptid=2224673" target="_blank">qratosones1337 发表于 2024-12-27 18:07</a>

说明泥潭喜欢不懂装懂的懂哥太多了，啥都想插一句嘴，然后自己又根本不懂（甚至可能都没到一知半解的地步 ...</blockquote>
乐，在跑实验罢了，哪个一线算法天天追论文不做业务

*****

####  御姐控之耻  
##### 46#       发表于 2024-12-27 18:15

上联：一艘两攻共三架飞机四款新品搞得五角大楼六神无主七上八下酒后加班十分难受

下联：十点九分看八方网友七彩贺图庆祝六代战机五湖纵横四海三山两府沸腾一等先进。


*****

####  moekyo  
##### 47#       发表于 2024-12-27 18:18

忽然想起，之前我看到最搞笑的是之前千问2.5出来的时候，我在推上搜，看到一个日本人对千问回答他说**是中国的无能狂怒<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  Pz079  
##### 48#       发表于 2024-12-27 18:24

从语文的角度来看，这篇文章是否是软文暂且不论，但前后逻辑混乱矛盾，的确需要打回去重写。文章以西大制造业衰退，没人研发硬件为开篇，批判“软件吞噬世界”，然后拉上宇树蹭热度，还以为要为我国博兴的制造产业呐喊，结果最后话锋一转落脚到给一个量化基金开发的AI模型张目，别忽悠大众行吗，你这个量化基金的AI项目不是你上面批判的软件么，还是个搞金融出身的软件服务，怎么三五行文字之后你都不知道自己前面说的那么多废话了？


*****

####  双刀少女  
##### 49#       发表于 2024-12-27 18:30

别的不懂，幻方跳到llm也能吹是眼力吗 之前还全网群嘲来着

*****

####  longrider  
##### 50#       发表于 2024-12-27 18:34

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67035537&amp;ptid=2224673" target="_blank">出逃白鲸 发表于 2024-12-27 16:29</a>

楼主没贴作者名字，个人凭感觉这个作者肯定不是制造业的，说了半天很空洞。

观点也许对，但内容空，套话多 ...</blockquote>
作者是著名微博/X国师[@阑夕](https://bbs.saraba1st.com/2b/home.php?mod=space&amp;uid=147804)


*****

####  迷路的石头  
##### 51#       发表于 2024-12-27 19:09

<blockquote>Van夫膜开 发表于 2024-12-27 16:28
从搞量化私募直接转行搞LLM，这个决心和眼界是真的牛逼</blockquote>
啥决心啊，20/21年幻方牛市里基金效益好，老总信心来了就梭哈了10000张A100搞深度学习挖因子，结果整的过拟合效益回撤了50%。当时都在嘲讽他们步子太大扯着蛋。

结果老登算力禁运后这10000张卡瞬间成了香饽饽，就顺势转到AI了


*****

####  迷路的石头  
##### 52#       发表于 2024-12-27 19:13

<blockquote>泰坦失足 发表于 2024-12-27 17:48
这玩意尺寸是671B，啥卡能放下啊. llama 3.2的405b都挺抽象的了.</blockquote>
幻方因为机缘巧合有10000张A100，所以AI发展还是要靠算力


*****

####  迷路的石头  
##### 53#       发表于 2024-12-27 19:16

<blockquote>yuialon 发表于 2024-12-27 17:03
纯软广，预训练技术路线已经到头了

下一代路线如果摸索出来，预训练直接被扫进垃圾桶

</blockquote>
没有证监会也会转

金融数据这种信噪比极低的数据搞深度学习只能搞出一堆过拟合。上了A100后幻方的业绩直接过山车。再加上美国禁运，国内在也搞不到这么多卡，转AI就是个顺势而为的事了

*****

####  ymm1030  
##### 54#       发表于 2024-12-27 19:20

就算软文怎么了，黑猴做的那么牛逼也需要宣传啊

—— 来自 [S1Fun](https://s1fun.koalcat.com)


*****

####  overflowal  
##### 55#       发表于 2024-12-27 19:22

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036324&amp;ptid=2224673" target="_blank">yanjunle 发表于 2024-12-27 18:13</a>
deepseek-v3发布最思细恐极的一点不是涨价预告吗，不知道为什么没看到什么相关的讨论。

幻方是今年这轮api ...</blockquote>
硬件不是发展停滞的。未来有更便宜更强的推理硬件完全是可能的。

—— 来自 Xiaomi 23049RAD8C, Android 14上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2-play


*****

####  FeteFrumoase  
##### 56#       发表于 2024-12-27 19:34

<blockquote>泰坦失足 发表于 2024-12-27 17:48
这玩意尺寸是671B，啥卡能放下啊. llama 3.2的405b都挺抽象的了.</blockquote>
当然是分布多卡系统喽笑

只能付费购买接口


*****

####  qratosones1337  
##### 57#       发表于 2024-12-27 19:37

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036324&amp;ptid=2224673" target="_blank">yanjunle 发表于 2024-12-27 18:13</a>
deepseek-v3发布最思细恐极的一点不是涨价预告吗，不知道为什么没看到什么相关的讨论。

幻方是今年这轮api ...</blockquote>
从GPT的百分之一涨到了50分之一，如涨

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.92

*****

####  emmerMK3  
##### 58#       发表于 2024-12-27 19:39

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036436&amp;ptid=2224673" target="_blank">longrider 发表于 2024-12-27 18:34</a>

作者是著名微博/X国师@阑夕</blockquote>
一下子就合理了，这种瞎**扯淡不懂装懂的味道

*****

####  qratosones1337  
##### 59#       发表于 2024-12-27 19:39

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67036720&amp;ptid=2224673" target="_blank">overflowal 发表于 2024-12-27 19:22</a>
硬件不是发展停滞的。未来有更便宜更强的推理硬件完全是可能的。

—— 来自 Xiaomi 23049RAD8C, Android ...</blockquote>
我猜现在可能已经在用昇腾了，毕竟MoE对于大显存廉价推理卡是重大利好，然后这次昇腾推理镜像也跟着一起首发就有了。三万块钱一张的Atlas300I跑7B模型效费比打不过4090，但是跑这玩意那可就优势太大了。

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.92

